{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports and .py file import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('../assets')\n",
    "import ames as ames\n",
    "os.chdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max columns and rows for easier viewing of certain operations below\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSVs into two different dataframes\n",
    "\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read in the training and testing data into two separate dataframes since I would have to clean/map and preprocess the data in the same method for both datasets. I then dropped two outlier rows using the .drop() function below. The second .drop() function doesn't actually do anything since the two datapoints that are dropped in the first function are the same that would have been dropped in the second. However, I wanted to include functions in case I ever expanded the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outlier house based on bsmt_sf and gr_liv_area \n",
    "# https://www.geeksforgeeks.org/drop-rows-from-the-dataframe-based-on-certain-condition-applied-on-a-column/\n",
    "\n",
    "df_train.drop(df_train[df_train['Total Bsmt SF'] > 5000].index, inplace = True)\n",
    "df_train.drop(df_train[df_train['Gr Liv Area'] > 5000].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I ran my two dataframes through the two functions in my Python file. The first function, ames.rename(), renamed all the columns and trimmed the dataset to just the columns I was interested in. This was applied to both dataframes using an if/else due to the df_test dataframe not having a SalePrice column. The second function, ames.map(), took care of filling NAs, mapping all of the columns categories that needed to be adjusted, and recategorizing certain quality or condition metrics that I wanted to combine. One other adjustment I made in my mapping function was to rewrite certain values of cond_1 if the cond_2 value was a worse quality. While most of the greater negative impacting conditions were listed in cond_1, I used this mapping to be able to drop the cond_2 column to simplify my model and only focus on the worst conditions. I also processed several feature combinations and interaction terms in my Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_renamed = ames.rename(df_train)\n",
    "df_test_renamed = ames.rename(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleaned = ames.map(df_train_renamed)\n",
    "df_test_cleaned = ames.map(df_test_renamed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I saved my renamed and mapped data to new CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cleaned.to_csv('../data/test_cleaned.csv', index=False)\n",
    "df_train_cleaned.to_csv('../data/train_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
